{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jumanji\n",
    "from jumanji.wrappers import AutoResetWrapper\n",
    "import flax.linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_jax(obs):\n",
    "    return jnp.concatenate([obs.ems.x1,obs.ems.x2,\n",
    "                        obs.ems.y1,obs.ems.y2,\n",
    "                        obs.ems.z1,obs.ems.z2,\n",
    "                        obs.ems_mask.flatten(),obs.items.x_len,\n",
    "                        obs.items.y_len,obs.items.z_len,\n",
    "                        obs.items_mask.flatten(),obs.items_placed.flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifierCompact(nn.Module):\n",
    "    num_hidden : int   # Number of hidden neurons\n",
    "    num_outputs : int  # Number of output neurons\n",
    "\n",
    "    @nn.compact  # Tells Flax to look for defined submodules\n",
    "    def __call__(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        # while defining necessary layers\n",
    "        x = nn.Dense(features=self.num_hidden)(x)\n",
    "        x = nn.tanh(x)\n",
    "        x = nn.Dense(features=self.num_outputs)(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.21167278], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if works\n",
    "rng = jax.random.PRNGKey(0)\n",
    "model = SimpleClassifierCompact(num_hidden=64, num_outputs=1)\n",
    "# Printing the model shows its attributes\n",
    "# print(model)\n",
    "rng, init_rng = jax.random.split(rng, 2)\n",
    "inp = jnp.arange(380)  # Batch size 8, input size 2\n",
    "# Initialize the model\n",
    "params = model.init(init_rng, inp)\n",
    "# print(params)\n",
    "model.apply(params, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_jax(obs, action_jnp):\n",
    "    #flatten observation  p = flatten(timestep.observation)\n",
    "    # inside critic and actor by converting it to np.array(p) by actor you will get action\n",
    "\n",
    "    #initiate actor and critic\n",
    "     #actor = FeedForwardNN(380,800)\n",
    "     key = jax.random.PRNGKey(0)\n",
    "     key, subkey = jax.random.split(key)\n",
    "     \n",
    "     actor = SimpleClassifierCompact(num_hidden=64, num_outputs=800)\n",
    "     \n",
    "     params = actor.init(init_rng, inp)\n",
    "    \n",
    "     logits = actor.apply(params,obs)\n",
    "     valid_indices = jnp.nonzero(action_jnp)  # getting valid indicies\n",
    "     valid_logits = logits[valid_indices]  # getting proper valid action probablities\n",
    "     valid_logits_array = jnp.reshape(valid_logits, (-1,))  # reshapping it to make it 1D\n",
    "     index_mapping = [i for i, include in enumerate(action_jnp) if include] # mapping of valid actions on whole set of actions\n",
    "     # Gumbel's trick\n",
    "     key, subkey = jax.random.split(key)\n",
    "     u = jax.random.uniform(subkey, shape=valid_logits_array.shape) # generates random uniform values\n",
    "     \n",
    "     probs = valid_logits_array - jnp.log(-jnp.log(u)) # logits + random uniform noise\n",
    "     action = jnp.argmax(probs) # argmax of probs -> action id in filtered array from valid actions\n",
    "     action_id = index_mapping[action] # action index in the 800 size array from actor output\n",
    "     log_prob_action = jnp.log(action) # log probability of selected action\n",
    "     \n",
    "     return action_id, action, log_prob_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values for hyperparameters, will need to change later.\n",
    "\n",
    "timesteps_per_batch = 2  # timesteps per batch\n",
    "#self.max_timesteps_per_episode = 1600      # timesteps per episode\n",
    "gamma = 0.95\n",
    "n_updates_per_iteration = 5\n",
    "clip = 0.2     # As recommended by (Schulman, 2017)\n",
    "lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rtgs_jax(batch_rews): \n",
    "    # The rewards-to-go (rtg) per episode per batch to return.\n",
    "    # The shape will be (num timesteps per episode)\n",
    "    \n",
    "    batch_rtgs = jnp.array([])\n",
    "    \n",
    "    # Iterate through each episode backwards to maintain same order in batch_rtgs\n",
    "    for ep_rews in reversed(batch_rews):\n",
    "      discounted_reward = 0 # The discounted reward so far\n",
    "      for rew in reversed(ep_rews):\n",
    "        discounted_reward = rew + discounted_reward * gamma\n",
    "        batch_rtgs = jnp.insert(batch_rtgs, 0, discounted_reward)\n",
    "        \n",
    "        #batch_rtgs.append(discounted_reward)\n",
    "      #batch_rtgs = jnp.array(batch_rtgs[::-1])\n",
    "      \n",
    "    return batch_rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
      "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:172: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return asarray(x, dtype=self.dtype)\n",
      "/usr/users/bdmagr5/hernandez/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:172: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return asarray(x, dtype=self.dtype)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/array.py:213\u001b[0m, in \u001b[0;36mArrayImpl.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m     batch_lens \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mappend(batch_lens, ep_t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m# plus 1 because timestep starts at 0\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     batch_rews \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mappend(batch_rews, ep_rews)\n\u001b[0;32m---> 60\u001b[0m batch_rtgs \u001b[39m=\u001b[39m compute_rtgs_jax(batch_rews)\n\u001b[1;32m     62\u001b[0m \u001b[39m#return batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens, rew\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 10\u001b[0m, in \u001b[0;36mcompute_rtgs_jax\u001b[0;34m(batch_rews)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m ep_rews \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(batch_rews):\n\u001b[1;32m      9\u001b[0m   discounted_reward \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39m# The discounted reward so far\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m   \u001b[39mfor\u001b[39;00m rew \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39;49m(ep_rews):\n\u001b[1;32m     11\u001b[0m     discounted_reward \u001b[39m=\u001b[39m rew \u001b[39m+\u001b[39m discounted_reward \u001b[39m*\u001b[39m gamma\n\u001b[1;32m     12\u001b[0m     batch_rtgs \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39minsert(batch_rtgs, \u001b[39m0\u001b[39m, discounted_reward)\n",
      "File \u001b[0;32m~/miniconda3/envs/marita/lib/python3.8/site-packages/jax/_src/array.py:215\u001b[0m, in \u001b[0;36mArrayImpl.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mlen() of unsized object\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "env = jumanji.make(\"BinPack-toy-v0\")\n",
    "\n",
    "\n",
    "# Rollout function\n",
    "batch_obs = jnp.array([])        # batch observations\n",
    "batch_acts = jnp.array([])       # batch actions\n",
    "batch_log_probs = jnp.array([])  # log probs of each action\n",
    "batch_rews = jnp.array([])       # batch rewards\n",
    "batch_rtgs = jnp.array([])       # batch rewards-to-go\n",
    "batch_lens = jnp.array([])       # episodic lengths in batch\n",
    "\n",
    "step_fn = jax.jit(env.step)\n",
    "reset_fn = jax.jit(env.reset)\n",
    "t = jnp.array(0, dtype=jnp.int32)\n",
    "\n",
    "while t < timesteps_per_batch:\n",
    "    # Rewards this episode\n",
    "    ep_rews = jnp.array([])\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    \n",
    "    #jax.jit(env.reset)(key)\n",
    "    state, timestep = jax.jit(env.reset)(key)\n",
    "    \n",
    "    ep_t = jnp.array(0, dtype=jnp.int32)\n",
    "    rew = jnp.array(0.0, dtype=jnp.int32)\n",
    "\n",
    "    while rew == 0.0:\n",
    "        # Increment timesteps ran this batch so far\n",
    "        t += 1\n",
    "        \n",
    "        obs = flatten_jax(timestep.observation)  # Collect observation\n",
    "        batch_obs = jnp.append(batch_obs, obs)\n",
    "    \n",
    "        num_ems, num_items = env.action_spec().num_values\n",
    "        action_mask = timestep.observation.action_mask.flatten()\n",
    "        action_jnp = jnp.array(action_mask, dtype=jnp.float32)\n",
    "\n",
    "        ems_item_id, action_,log_prob  = get_action_jax(obs,action_jnp)\n",
    "        ems_id, item_id = jnp.divmod(ems_item_id, num_items)\n",
    "\n",
    "        # Wrap the action as a jax array of shape (2,)\n",
    "        action = jnp.array([ems_id, item_id])\n",
    "\n",
    "        step_fn = jax.jit(env.step)\n",
    "        reset_fn = jax.jit(env.reset)\n",
    "        state, timestep = step_fn(state, action)\n",
    "        \n",
    "        rew = jnp.array(timestep.reward.flatten())[0]\n",
    "        ep_rews = jnp.append(ep_rews, rew)\n",
    "        batch_acts = jnp.append(batch_acts,action_)\n",
    "        batch_log_probs = jnp.append(batch_log_probs, log_prob)\n",
    "        \n",
    "        ep_t += 1\n",
    "    \n",
    "    # Collect episodic length and rewards\n",
    "    batch_lens = jnp.append(batch_lens, ep_t + 1) # plus 1 because timestep starts at 0\n",
    "    batch_rews = jnp.append(batch_rews, ep_rews)\n",
    "\n",
    "batch_rtgs = compute_rtgs_jax(batch_rews)\n",
    "\n",
    "#return batch_obs, batch_acts, batch_log_probs, batch_rtgs, batch_lens, rew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(self, batch_obs, batch_acts):\n",
    "    # Query critic network for a value V for each obs in batch_obs.\n",
    "    V = self.critic(batch_obs).squeeze()\n",
    "    #print(\"in evaluate , value function after critic \", V)\n",
    "    \n",
    "    # Calculate the log probabilities of batch actions using most recent actor network.\n",
    "    # This segment of code is similar to that in get_action()\n",
    "    batch_logits = self.actor(batch_obs)\n",
    "    log_softmax_probs = jax.nn.log_softmax(batch_logits)\n",
    "\n",
    "    log_probs = log_softmax_probs[batch_acts]\n",
    "    # Return predicted values V and log probs log_probs\n",
    "    return V, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FrozenDict' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m mean \u001b[39m=\u001b[39m actor\u001b[39m.\u001b[39minit(init_rng, inp)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create our Multivariate Normal Distribution\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m dist \u001b[39m=\u001b[39m Categorical(mean)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Sample an action from the distribution and get its log prob\u001b[39;00m\n\u001b[1;32m      9\u001b[0m action \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39msample()\n",
      "File \u001b[0;32m~/miniconda3/envs/marita/lib/python3.8/site-packages/torch/distributions/categorical.py:55\u001b[0m, in \u001b[0;36mCategorical.__init__\u001b[0;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEither `probs` or `logits` must be specified, but not both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m probs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     \u001b[39mif\u001b[39;00m probs\u001b[39m.\u001b[39;49mdim() \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     56\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`probs` parameter must be at least one-dimensional.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobs \u001b[39m=\u001b[39m probs \u001b[39m/\u001b[39m probs\u001b[39m.\u001b[39msum(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FrozenDict' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "actor = SimpleClassifierCompact(num_hidden=64, num_outputs=800)   \n",
    "mean = actor.init(init_rng, inp)\n",
    "\n",
    "# Create our Multivariate Normal Distribution\n",
    "dist = Categorical(mean)\n",
    "# Sample an action from the distribution and get its log prob\n",
    "action = dist.sample()\n",
    "log_prob = dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c185be73de2efb290183dc2463f09a8777cdf0905db2255d30393f376d4ea358"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
