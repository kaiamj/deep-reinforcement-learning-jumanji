{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1GnlCxvjy4A1gsfeMarfb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiamj/deep-reinforcement-learning-jumanji/blob/main/ppo_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/instadeepai/jumanji.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMWu06-soreA",
        "outputId": "3ee0eafc-03ad-4b4f-bd7e-0135c3be83fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/instadeepai/jumanji.git\n",
            "  Cloning https://github.com/instadeepai/jumanji.git to /tmp/pip-req-build-aqoxg89g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/instadeepai/jumanji.git /tmp/pip-req-build-aqoxg89g\n",
            "  Resolved https://github.com/instadeepai/jumanji.git to commit 10958866909d434ba50edc1915247e4cebc3cb3e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax>=0.2.26 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.3.25)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (4.4.0)\n",
            "Collecting matplotlib>=3.3.4\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-env>=1.5\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Collecting brax>=0.0.10\n",
            "  Downloading brax-0.1.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.3/471.3 KB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gym>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.25.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.74 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (1.21.6)\n",
            "Collecting chex>=0.1.3\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.0.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygame>=2.0.0\n",
            "  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.51.1)\n",
            "Collecting jaxopt\n",
            "  Downloading jaxopt-0.5.5-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting pytinyrenderer\n",
            "  Downloading pytinyrenderer-0.0.13-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.7.3)\n",
            "Collecting mujoco\n",
            "  Downloading mujoco-2.3.1.post1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax\n",
            "  Downloading flax-0.6.4-py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 KB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (2.11.3)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh==3.9.35\n",
            "  Downloading trimesh-3.9.35-py3-none-any.whl (639 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m639.3/639.3 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from trimesh==3.9.35->brax>=0.0.10->jumanji==0.1.4) (57.4.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.3->jumanji==0.1.4) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.3->jumanji==0.1.4) (0.1.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (6.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (2.2.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (0.0.8)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.2.26->jumanji==0.1.4) (3.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (1.4.4)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (21.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym>=0.22.0->jumanji==0.1.4) (3.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->jumanji==0.1.4) (1.15.0)\n",
            "Collecting tensorstore\n",
            "  Downloading tensorstore-0.1.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.4) (6.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.4) (1.0.4)\n",
            "Collecting rich>=11.1\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orbax\n",
            "  Downloading orbax-0.1.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->brax>=0.0.10->jumanji==0.1.4) (2.0.1)\n",
            "Collecting glfw\n",
            "  Downloading glfw-2.5.6-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.8/dist-packages (from mujoco->brax>=0.0.10->jumanji==0.1.4) (3.1.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->brax>=0.0.10->jumanji==0.1.4) (3.19.6)\n",
            "Collecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.8/dist-packages (from orbax->flax->brax>=0.0.10->jumanji==0.1.4) (5.10.2)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.8/dist-packages (from orbax->flax->brax>=0.0.10->jumanji==0.1.4) (1.0.0)\n",
            "Collecting cached_property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: jumanji\n",
            "  Building wheel for jumanji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jumanji: filename=jumanji-0.1.4-py3-none-any.whl size=166864 sha256=012552b480ab4fe75646fdb919f355f733f2fc8bcf2f7e4b2c0f7d8fccea48b0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n1wr9x82/wheels/df/c6/15/caef8b041b929f4f3b7a55a217c00f24c6931fe57ae40d9bd9\n",
            "Successfully built jumanji\n",
            "Installing collected packages: pytinyrenderer, glfw, dataclasses, cached_property, trimesh, tensorstore, tensorboardX, pygments, pygame, Pillow, mujoco, mdurl, fonttools, dm-env, contourpy, matplotlib, markdown-it-py, rich, jaxopt, chex, optax, orbax, flax, brax, jumanji\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.4.0 brax-0.1.1 cached_property-1.5.2 chex-0.1.5 contourpy-1.0.7 dataclasses-0.6 dm-env-1.6 flax-0.6.4 fonttools-4.38.0 glfw-2.5.6 jaxopt-0.5.5 jumanji-0.1.4 markdown-it-py-2.1.0 matplotlib-3.6.3 mdurl-0.1.2 mujoco-2.3.1.post1 optax-0.1.4 orbax-0.1.1 pygame-2.1.2 pygments-2.14.0 pytinyrenderer-0.0.13 rich-13.3.1 tensorboardX-2.5.1 tensorstore-0.1.31 trimesh-3.9.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "upuzSlMOHB8T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "from jax import vmap\n",
        "import jax.numpy as jnp\n",
        "import jumanji\n",
        "from jumanji.wrappers import AutoResetWrapper\n",
        "import flax.linen as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def flatten_jax(obs):\n",
        "    return jnp.concatenate([obs.ems.x1,obs.ems.x2,\n",
        "                        obs.ems.y1,obs.ems.y2,\n",
        "                        obs.ems.z1,obs.ems.z2,\n",
        "                        obs.ems_mask.flatten(),obs.items.x_len,\n",
        "                        obs.items.y_len,obs.items.z_len,\n",
        "                        obs.items_mask.flatten(),obs.items_placed.flatten()])"
      ],
      "metadata": {
        "id": "Ya00mTGWHGBJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1U1flyZ5sU2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# flax nn"
      ],
      "metadata": {
        "id": "J0HQrwd8sWpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn \n",
        "import optax\n",
        "\n",
        "class SimpleClassifierCompact(nn.Module):\n",
        "    num_hidden : int   # Number of hidden neurons\n",
        "    num_outputs : int  # Number of output neurons\n",
        "\n",
        "    @nn.compact  # Tells Flax to look for defined submodules\n",
        "    def __call__(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        # while defining necessary layers\n",
        "        x = nn.Dense(features=self.num_hidden)(x)\n",
        "        x = nn.tanh(x)\n",
        "        x = nn.Dense(features=self.num_outputs)(x)\n",
        "        return x\n",
        "def critic_calculate_loss( state, V,batch_rtgs):\n",
        "    #logits = critic_state.apply_fn(params, data).squeeze(axis=-1)\n",
        "    loss = optax.sigmoid_binary_cross_entropy(V, batch_rtgs).mean()\n",
        "    #print(\"loss of critic \", loss)\n",
        "    return loss\n",
        "\n",
        "@jax.jit  # Jit the function for efficiency\n",
        "def critic_train_step(state, V,batch_rtgs):\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(critic_calculate_loss,  # Function to calculate the loss\n",
        "                                 argnums=0  # Parameters are second argument of the function\n",
        "                                 #has_aux=False  # Function has additional outputs, here accuracy\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    loss, grads = grad_fn(state.params,V,batch_rtgs)\n",
        "    #print(\"gradient of critic \",grads,\" type \", type(grads))\n",
        "\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state\n",
        "def actor_calculate_loss( state, surr1,surr2):\n",
        "    #logits = critic_state.apply_fn(params, data).squeeze(axis=-1)\n",
        "    actor_loss = (-jnp.minimum(surr1, surr2)).mean()\n",
        "    #print(\"actor loss \",actor_loss)\n",
        "    return actor_loss\n",
        "\n",
        "@jax.jit  # Jit the function for efficiency\n",
        "def actor_train_step(state,  surr1,surr2):\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(actor_calculate_loss,  # Function to calculate the loss\n",
        "                                 argnums=0  # Parameters are second argument of the function\n",
        "                                 #has_aux=False  # Function has additional outputs, here accuracy\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    loss, grads = grad_fn(state.params, surr1,surr2)\n",
        "    #print(\"gradient of actor \",grads,\" type \", type(grads))\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state\n",
        "#critic_state, loss = critic_train_step(critic_state, data)"
      ],
      "metadata": {
        "id": "XOsEpJk7HMjx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flax.training import train_state\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "class PPO:\n",
        "  def __init__(self,env):\n",
        "    self._init_hyperparameters()\n",
        "    self.env = env\n",
        "    \n",
        "    #initiate actor and critic =========================================================\n",
        "    \n",
        "\n",
        "    self.optimizer = optax.sgd(learning_rate=self.lr)\n",
        "\n",
        "    self.actor = SimpleClassifierCompact(num_hidden=64, num_outputs=self.act_dim)\n",
        "    self.critic = SimpleClassifierCompact(num_hidden=64, num_outputs=1)\n",
        "    \n",
        "    self.params = self.actor.init(self.subkey, jnp.arange(self.obs_dim))\n",
        "    self.cparams = self.critic.init(self.subkey, jnp.arange(self.obs_dim))\n",
        "\n",
        "    self.actor_state = train_state.TrainState.create(apply_fn=self.actor.apply,\n",
        "                                            params=self.params,\n",
        "                                            tx=self.optimizer)\n",
        "    self.critic_state = train_state.TrainState.create(apply_fn=self.critic.apply,\n",
        "                                            params=self.cparams,\n",
        "                                            tx=self.optimizer)\n",
        "     \n",
        "    #====================================================================================\n",
        "    \n",
        "    \n",
        "    \n",
        "  def _init_hyperparameters(self):\n",
        "    # Default values for hyperparameters, will need to change later.\n",
        "    self.timesteps_per_batch = 2  #4800            # timesteps per batch\n",
        "    #self.max_timesteps_per_episode = 1600      # timesteps per episode\n",
        "    self.gamma = 0.95\n",
        "    self.n_updates_per_iteration = 1\n",
        "    self.clip = 0.2 # As recommended by the paper\n",
        "    self.lr = 0.1\n",
        "\n",
        "    self.obs_dim = 380\n",
        "    self.act_dim = 800\n",
        "\n",
        "    self.key = jax.random.PRNGKey(0)\n",
        "    self.key, self.subkey = jax.random.split(self.key)\n",
        "\n",
        "\n",
        "  def compute_rtgs_jax(self, batch_rews): \n",
        "    # The rewards-to-go (rtg) per episode per batch to return.\n",
        "    # The shape will be (num timesteps per episode)\n",
        "    \n",
        "    batch_rtgs = jnp.array([])\n",
        "    #print(\"batch_rews \",batch_rews)\n",
        "    # Iterate through each episode backwards to maintain same order in batch_rtgs\n",
        "    for ep_rews in reversed(batch_rews):\n",
        "      discounted_reward = 0 # The discounted reward so far\n",
        "      #print(\" ep_rews \",ep_rews)\n",
        "      discounted_reward = ep_rews + discounted_reward * self.gamma\n",
        "      #print(\"discounted_reward \",discounted_reward)\n",
        "      batch_rtgs = jnp.insert(batch_rtgs, 0, discounted_reward)\n",
        "    #print(\"batch_rtgs\",batch_rtgs)\n",
        "    return batch_rtgs\n",
        "\n",
        "\n",
        " \n",
        "  def get_action_jax(self, obs, action_jnp):\n",
        "    #flatten observation  p = flatten(timestep.observation)\n",
        "    # inside critic and actor by converting it to np.array(p) by actor you will get action\n",
        "\n",
        "    #initiate actor and critic\n",
        "     #actor = FeedForwardNN(380,800)\n",
        "     logits = self.actor_state.apply_fn(self.actor_state.params, obs)\n",
        "    \n",
        "     valid_indices = jnp.nonzero(action_jnp)  # getting valid indicies\n",
        "     valid_logits = logits[valid_indices]  # getting proper valid action probablities\n",
        "     valid_logits_array = jnp.reshape(valid_logits, (-1,))  # reshapping it to make it 1D\n",
        "     index_mapping = [i for i, include in enumerate(action_jnp) if include] # mapping of valid actions on whole set of actions\n",
        "     # Gumbel's trick\n",
        "     \n",
        "     u = jax.random.uniform(self.subkey, shape=valid_logits_array.shape) # generates random uniform values\n",
        "     \n",
        "     probs = valid_logits_array - jnp.log(-jnp.log(u)) # logits + random uniform noise\n",
        "     action = jnp.argmax(probs) # argmax of probs -> action id in filtered array from valid actions\n",
        "     action_id = index_mapping[action] # action index in the 800 size array from actor output\n",
        "     log_prob_action = jnp.log(action) # log probability of selected action\n",
        "     \n",
        "     return action_id, action, log_prob_action\n",
        "  \n",
        "  def rollout(self):\n",
        "    # batch observations, batch actions, log probs of each action, batch rewards,batch rewards-to-go,episodic lengths in batch\n",
        "    batch_obs, batch_acts, batch_log_probs, batch_rews, batch_rtgs, batch_lens = jnp.array([]), jnp.array([]), jnp.array([]), jnp.array([]), jnp.array([]),jnp.array([])\n",
        "    batch_states = []\n",
        "    step_fn = jax.jit(self.env.step)\n",
        "    reset_fn = jax.jit(self.env.reset)\n",
        "    t = 0 \n",
        "    \n",
        "    while t < self.timesteps_per_batch: # Number of timesteps run so far this batch\n",
        "      # Rewards this episode\n",
        "      ep_rews = jnp.array([])\n",
        "      \n",
        "      \n",
        "      state, timestep = reset_fn(self.key)\n",
        "      ep_t = 1\n",
        "      rew = 0.0\n",
        "      while rew == 0.0:\n",
        "        batch_states.append(state)\n",
        "        obs = flatten_jax(timestep.observation)  # Collect observation\n",
        "        #print(\"obs  flat \",len(obs))\n",
        "        if t == 0 and ep_t == 1:\n",
        "          batch_obs = jnp.append(batch_obs, obs)\n",
        "        else:\n",
        "          batch_obs = jnp.vstack([batch_obs, obs])\n",
        "        #print(\"batch  \",batch_obs)\n",
        "        num_ems, num_items = self.env.action_spec().num_values\n",
        "        action_mask = timestep.observation.action_mask.flatten()\n",
        "        action_jnp = jnp.array(action_mask, dtype=jnp.float32)\n",
        "\n",
        "        ems_item_id, action_,log_prob  = self.get_action_jax(obs,action_jnp)\n",
        "        ems_id, item_id = jnp.divmod(ems_item_id, num_items)\n",
        "\n",
        "        action = jnp.array([ems_id, item_id])  # Wrap the action as a jax array of shape (2,)\n",
        "        #batch_states = jnp.append(batch_states, state)\n",
        "\n",
        "        state,timestep = step_fn(state, action)\n",
        "        rew = jnp.array(timestep.reward.flatten())[0]\n",
        "        #print(\" rew \", rew,\" type \", type(rew))\n",
        "        ep_rews = jnp.append(ep_rews, rew)\n",
        "        #print(\" ep_rews \",ep_rews )\n",
        "        batch_acts = jnp.append(batch_acts, action_)\n",
        "        batch_log_probs = jnp.append(batch_log_probs, log_prob)\n",
        "        ep_t += 1 # Increment timesteps ran this batch so far\n",
        "\n",
        "      t += ep_t\n",
        "      batch_rews = jnp.append(batch_rews, ep_rews) \n",
        "    \n",
        "    batch_rtgs = self.compute_rtgs_jax(batch_rews)\n",
        "    return batch_obs, batch_acts,batch_log_probs, batch_rtgs, t ,rew,batch_states\n",
        "\n",
        "  def learn(self, total_timesteps):\n",
        "    t_so_far = 0 # Timesteps simulated so far\n",
        "    episode_reward = jnp.array([])\n",
        "    while t_so_far < total_timesteps:              # ALG STEP \n",
        "      batch_obs, batch_acts, batch_log_probs, batch_rtgs, t, rew,batch_states = self.rollout()\n",
        "      # print(\"len  of batch obs and obs of episode itself\",len(batch_obs),batch_obs)\n",
        "      # print(\"batch_ act \", batch_acts)\n",
        "      # print(\"batch_log_prob \",batch_log_probs)\n",
        "      # print(\"batch_rtg \", batch_rtgs)\n",
        "      \n",
        "      episode_reward = jnp.append(episode_reward, rew)\n",
        "      t_so_far += t # Calculate how many timesteps we collected this batch   \n",
        "      V, _ = self.evaluate(batch_obs, batch_acts)\n",
        "      A_k = batch_rtgs - V # ALG STEP 5 Calculate advantage\n",
        "      A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10) # Normalize advantages\n",
        "      for i in range(self.n_updates_per_iteration):\n",
        "        V, curr_log_probs = self.evaluate(batch_obs, batch_acts)\n",
        "        ratios = jax.lax.exp(curr_log_probs - batch_log_probs)   # Calculate ratios\n",
        "        surr1 = ratios * A_k  # Calculate surrogate losses\n",
        "        surr2 = jax.lax.clamp( 1 - self.clip, ratios, 1 + self.clip) * A_k\n",
        "        #print(surr1,surr2,\"  surrrrrr  \",\"  ratios \",ratios, \" ak \",A_k)\n",
        "        #======================================================================================================\n",
        "        self.actor_state = actor_train_step(self.actor_state, surr1, surr2)\n",
        "        self.critic_state = critic_train_step(self.critic_state, V, batch_rtgs)\n",
        "        #=====================================================================================================\n",
        "        \n",
        "        \n",
        "    return batch_states, episode_reward\n",
        "    \n",
        "  def evaluate(self, batch_obs,batch_acts):\n",
        "    # Query critic network for a value V for each obs in batch_obs.\n",
        "    #V = self.critic(batch_obs).squeeze()\n",
        "#vmap(sum_samples)(data)\n",
        "    #V = vmap(self.critic_state.apply_fn)(self.critic_state.params, batch_obs)#.squeeze(axis=-1)\n",
        "    V = jnp.array([])\n",
        "    #batch_logits = jnp.array([])\n",
        "    for i in batch_obs:\n",
        "      \n",
        "      # print(\"len of actor param \", len(self.actor_state.params),self.actor_state.params)\n",
        "\n",
        "      #batch_logits = jnp.append(batch_logits,self.actor_state.apply_fn(self.actor_state.params, i))\n",
        "      # print(\"len of out actor \",len(outa), outa )\n",
        "      # print(\"critic param \",len(self.critic_state.params),self.critic_state.params)\n",
        "      # print(\"obs \", len(i))\n",
        "      V = jnp.append(V,self.critic_state.apply_fn(self.critic_state.params, i))\n",
        "    #print(\"Value func \", V)\n",
        "    #print(\"batch_logits \",batch_logits)\n",
        "    # Calculate the log probabilities of batch actions using most \n",
        "    # recent actor network.  # This segment of code is similar to that in get_action()\n",
        "    #batch_logits = self.actor_state.apply_fn(self.actor_state.params, batch_obs).squeeze(axis=-1)\n",
        "    # rescaling \n",
        "    #log_softmax_probs = jax.nn.log_softmax(batch_logits)\n",
        "    # print(\"log_softmax_probs len \",type(log_softmax_probs),log_softmax_probs)\n",
        "    # print(\"batch_ actions \", type(batch_acts),batch_acts)\n",
        "    log_probs = jnp.log(batch_acts)\n",
        "\n",
        "    return V, log_probs  # Return predicted values V and log probs log_probs\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "UjzPa8LFHNvL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "env = jumanji.make(\"BinPack-toy-v0\")\n",
        "model = PPO(env)\n",
        "#batch_obs, batch_acts, batch_log_probs, batch_rtgs, t, rew = model.rollout()\n",
        "  \n",
        "%time batch_states, episode_rewards = model.learn(1)\n",
        "#### with jit env , reset one episode \n",
        "# CPU times: user 7.4 s, sys: 103 ms, total: 7.5 s\n",
        "# Wall time: 7.1 s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-37ugMco8ka",
        "outputId": "9fd6ffde-915f-410f-8fc5-aa1739199b6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.7 s, sys: 796 ms, total: 22.5 s\n",
            "Wall time: 46.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eCgtIMmmJ1y_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}