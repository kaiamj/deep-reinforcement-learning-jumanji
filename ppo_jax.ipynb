{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtF9eiD8NqpIy5tSfLd1X2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiamj/deep-reinforcement-learning-jumanji/blob/main/ppo_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = np.array([])\n",
        "b2 = np.array([2.0,52.0,4.0,7.0])\n",
        "b = np.append(b,b2)\n",
        "s =np.vstack([b,b2])"
      ],
      "metadata": {
        "id": "PGS90rmFxA_9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b2 = np.array([2.0,52.0,4.0,7.0])\n",
        "b3 = jnp.log(b2)"
      ],
      "metadata": {
        "id": "GQXCWQxuk7es"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions import Categorical\n",
        "import torch\n",
        "p = [2, 50, 90]\n",
        "dist = Categorical(probs=torch.tensor(p))\n",
        "\n",
        "# dist = Categorical(torch.tensor([1,23,4,5,2]))\n",
        "# print(\"out cat  \",dist )\n",
        "log_probs = dist.log_prob(torch.tensor([2,5,6]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "eWSeHI6d3X17",
        "outputId": "78cea62a-89a7-4f5e-b858-938d0c850af2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3f8bdee277c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# dist = Categorical(torch.tensor([1,23,4,5,2]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(\"out cat  \",dist )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/categorical.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0;34m\"Expected value argument \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;34mf\"({type(value).__name__} of shape {tuple(value.shape)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected value argument (Tensor of shape (3,)) to be within the support (IntegerInterval(lower_bound=0, upper_bound=2)) of the distribution Categorical(probs: torch.Size([3])), but found invalid values:\ntensor([2, 5, 6])"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "c = jax.random.categorical(key, b2)"
      ],
      "metadata": {
        "id": "1_I5OON-DZL5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JU-yBFoo29Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in s:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukA79ahNDRaH",
        "outputId": "0838dd9f-e724-462f-a49a-c694ac9e37c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2. 52.  4.  7.]\n",
            "[ 2. 52.  4.  7.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.numpy as np\n",
        "from jax import random,vmap\n",
        "\n",
        "def sum_samples(layer):\n",
        "    (dw, db) = layer\n",
        "    (dw, db) = (np.sum(dw, axis=0), np.sum(db, axis=0))\n",
        "    return np.array([dw, db])\n",
        "\n",
        "key = random.PRNGKey(1701)\n",
        "data = random.uniform(key, (10, 2, 20))\n",
        "\n",
        "result = vmap(sum_samples)(data)\n",
        "print(result.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj-fD9dERrmS",
        "outputId": "d6f8c3a9-69cd-4b9a-e97c-f813fe670bbc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = random.PRNGKey(1701)\n",
        "i = jax.random.normal(key,(1,380))"
      ],
      "metadata": {
        "id": "gj15A-3NVWWR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.random.categorical(key, logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVXY2__HR2Bt",
        "outputId": "46a7c260-1037-4ed1-8e61-045f517d8933"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[9.10784841e-01, 9.00956511e-01, 4.08365369e-01,\n",
              "               7.35841751e-01, 8.00690055e-01, 5.39383888e-02,\n",
              "               6.56396985e-01, 4.83418584e-01, 9.21171427e-01,\n",
              "               8.80449653e-01, 3.09709907e-01, 7.77801037e-01,\n",
              "               8.92477393e-01, 9.61626410e-01, 9.99255180e-01,\n",
              "               1.37289643e-01, 6.37572408e-01, 5.11163592e-01,\n",
              "               4.69839931e-01, 9.16154027e-01],\n",
              "              [8.52572918e-01, 7.37004638e-01, 1.45462155e-01,\n",
              "               4.26606178e-01, 8.60655069e-01, 4.40370917e-01,\n",
              "               4.21858072e-01, 2.93413281e-01, 1.59504175e-01,\n",
              "               6.33872390e-01, 5.46415687e-01, 6.35575294e-01,\n",
              "               8.22544098e-06, 7.14041829e-01, 3.95977378e-01,\n",
              "               5.39646029e-01, 8.98891687e-02, 4.99658227e-01,\n",
              "               2.09191322e-01, 5.51786423e-02]],\n",
              "\n",
              "             [[3.44063640e-01, 7.59088278e-01, 8.75769258e-01,\n",
              "               2.05692530e-01, 7.68872142e-01, 4.85912561e-02,\n",
              "               3.76576543e-01, 1.59282923e-01, 6.66122317e-01,\n",
              "               7.68826008e-02, 7.47599483e-01, 4.84158754e-01,\n",
              "               1.13964438e-01, 1.42050505e-01, 5.98236561e-01,\n",
              "               2.87550688e-01, 5.98336101e-01, 6.72990084e-01,\n",
              "               6.53721213e-01, 9.38372016e-01],\n",
              "              [7.06639409e-01, 4.39164758e-01, 6.90080285e-01,\n",
              "               3.29041600e-01, 8.50655437e-01, 5.29577136e-01,\n",
              "               9.46985483e-02, 9.70868230e-01, 6.78333998e-01,\n",
              "               9.48850155e-01, 1.83965802e-01, 3.29248190e-01,\n",
              "               5.87361813e-01, 1.05456710e-01, 3.62094283e-01,\n",
              "               2.96609163e-01, 6.69184089e-01, 7.38373280e-01,\n",
              "               7.08543897e-01, 5.80912709e-01]],\n",
              "\n",
              "             [[7.53916025e-01, 6.01453424e-01, 9.61362123e-02,\n",
              "               3.91509533e-02, 8.38008046e-01, 3.42855811e-01,\n",
              "               1.39293432e-01, 7.25058198e-01, 1.85465813e-02,\n",
              "               3.73671174e-01, 3.19508672e-01, 5.89853883e-01,\n",
              "               2.29132295e-01, 8.14817071e-01, 4.01984572e-01,\n",
              "               1.00419760e-01, 8.46624374e-02, 2.55802989e-01,\n",
              "               3.62974286e-01, 1.98571444e-01],\n",
              "              [7.64784455e-01, 5.54041386e-01, 3.31485033e-01,\n",
              "               4.54690218e-01, 2.15105534e-01, 4.58979487e-01,\n",
              "               3.99899483e-02, 4.10602689e-01, 6.76079154e-01,\n",
              "               5.63951492e-01, 1.42629862e-01, 3.13669801e-01,\n",
              "               4.68075275e-01, 7.68883944e-01, 7.19795346e-01,\n",
              "               5.09566784e-01, 9.53910947e-01, 8.93937349e-02,\n",
              "               7.68657446e-01, 5.94772935e-01]],\n",
              "\n",
              "             [[2.50203609e-02, 9.04143810e-01, 3.63489151e-01,\n",
              "               1.46851540e-02, 9.49601531e-01, 7.04073429e-01,\n",
              "               1.94252133e-01, 7.69754529e-01, 9.94401336e-01,\n",
              "               6.00893617e-01, 1.63211823e-02, 2.03214884e-01,\n",
              "               3.59423995e-01, 3.59955907e-01, 8.77693176e-01,\n",
              "               1.21368289e-01, 4.93526459e-03, 4.09233093e-01,\n",
              "               5.13746858e-01, 5.28852940e-01],\n",
              "              [4.25690413e-02, 3.62619162e-02, 6.80603623e-01,\n",
              "               5.21394730e-01, 7.13649631e-01, 8.67375970e-01,\n",
              "               4.65170145e-02, 8.64141703e-01, 2.53773928e-01,\n",
              "               5.09130359e-01, 7.22360134e-01, 6.89697981e-01,\n",
              "               5.51480293e-01, 3.06105971e-01, 6.55730486e-01,\n",
              "               1.43139482e-01, 2.35949636e-01, 2.43965864e-01,\n",
              "               6.24054074e-01, 3.37000847e-01]],\n",
              "\n",
              "             [[3.09192061e-01, 5.72095156e-01, 9.98410344e-01,\n",
              "               3.03847909e-01, 6.50588870e-01, 6.78243041e-01,\n",
              "               6.56285524e-01, 6.49011731e-01, 1.64618731e-01,\n",
              "               8.32495809e-01, 2.34570742e-01, 8.78357887e-02,\n",
              "               6.81891799e-01, 8.89623046e-01, 7.08889127e-01,\n",
              "               6.27156496e-02, 5.34145951e-01, 3.43765020e-01,\n",
              "               7.07569003e-01, 3.49135756e-01],\n",
              "              [3.52290154e-01, 9.02613282e-01, 3.83831263e-02,\n",
              "               1.98168755e-01, 5.91781855e-01, 4.61029887e-01,\n",
              "               6.43818974e-01, 7.88012624e-01, 8.03813338e-01,\n",
              "               7.28622556e-01, 8.55121970e-01, 8.64034057e-01,\n",
              "               2.62810111e-01, 4.82339025e-01, 5.86860299e-01,\n",
              "               9.68924761e-02, 9.08169627e-01, 5.16362548e-01,\n",
              "               7.96468616e-01, 7.61595488e-01]],\n",
              "\n",
              "             [[6.13742828e-01, 5.24129152e-01, 7.87760019e-02,\n",
              "               6.41989946e-01, 8.90257955e-01, 4.91906643e-01,\n",
              "               5.00184536e-01, 8.53640437e-01, 7.96164632e-01,\n",
              "               8.14259171e-01, 7.70532012e-01, 1.95277214e-01,\n",
              "               5.29714584e-01, 6.12041831e-01, 6.59668326e-01,\n",
              "               5.92953324e-01, 4.94185448e-01, 8.92581582e-01,\n",
              "               4.38647747e-01, 2.61825442e-01],\n",
              "              [8.77841830e-01, 4.72866654e-01, 9.89995837e-01,\n",
              "               5.12926459e-01, 5.95345497e-02, 1.02913260e-01,\n",
              "               2.88887024e-02, 8.34637642e-01, 4.39594984e-02,\n",
              "               7.97374249e-01, 2.25934148e-01, 9.04292107e-01,\n",
              "               1.87608004e-02, 5.15744925e-01, 8.20031881e-01,\n",
              "               4.34284329e-01, 7.10308790e-01, 1.79128289e-01,\n",
              "               9.15482640e-01, 6.17255330e-01]],\n",
              "\n",
              "             [[3.18474889e-01, 8.17909956e-01, 2.12130785e-01,\n",
              "               4.42916989e-01, 9.25580621e-01, 2.20725894e-01,\n",
              "               3.75087261e-02, 9.86585140e-01, 6.68431640e-01,\n",
              "               5.82841516e-01, 4.34761763e-01, 6.56974673e-01,\n",
              "               1.24411106e-01, 3.84944797e-01, 5.32364726e-01,\n",
              "               1.81761861e-01, 3.10273409e-01, 6.88444257e-01,\n",
              "               6.10430241e-02, 1.09232664e-01],\n",
              "              [1.41311049e-01, 3.48029971e-01, 1.65927172e-01,\n",
              "               2.66794205e-01, 6.06203794e-01, 7.96128511e-02,\n",
              "               9.28797722e-02, 3.11982393e-01, 7.61072636e-02,\n",
              "               9.52159166e-01, 2.26835132e-01, 1.92552209e-01,\n",
              "               7.57819414e-02, 6.87696457e-01, 8.71516824e-01,\n",
              "               3.12282443e-01, 2.47756958e-01, 6.30819321e-01,\n",
              "               5.49173236e-01, 9.85391736e-01]],\n",
              "\n",
              "             [[1.33571148e-01, 7.54435301e-01, 2.32061028e-01,\n",
              "               3.44546437e-01, 7.43454337e-01, 2.51678109e-01,\n",
              "               9.44656968e-01, 2.36420631e-01, 6.22006059e-01,\n",
              "               8.43002915e-01, 3.68518829e-01, 7.94597149e-01,\n",
              "               1.03322148e-01, 1.29909754e-01, 2.81952500e-01,\n",
              "               7.18468428e-01, 7.29023576e-01, 1.19452238e-01,\n",
              "               6.32119179e-01, 1.18969083e-01],\n",
              "              [9.61788893e-01, 2.50545621e-01, 1.07843757e-01,\n",
              "               5.22949457e-01, 5.20487189e-01, 4.77428913e-01,\n",
              "               4.13414836e-01, 7.91862845e-01, 4.46998239e-01,\n",
              "               3.03465962e-01, 5.91655850e-01, 5.45536876e-01,\n",
              "               5.68796396e-01, 2.74085283e-01, 9.54789042e-01,\n",
              "               1.13472700e-01, 8.69383574e-01, 2.32882500e-01,\n",
              "               3.06130648e-01, 1.57053947e-01]],\n",
              "\n",
              "             [[9.17449594e-01, 2.67053723e-01, 1.88641429e-01,\n",
              "               1.33090496e-01, 7.63668895e-01, 3.12337756e-01,\n",
              "               8.92650485e-01, 9.29988503e-01, 8.60538244e-01,\n",
              "               4.57568169e-01, 4.61078525e-01, 2.48217821e-01,\n",
              "               2.27879643e-01, 3.23737025e-01, 8.91143084e-02,\n",
              "               4.76294756e-01, 4.28268313e-01, 6.79367542e-01,\n",
              "               5.97333312e-01, 3.61006737e-01],\n",
              "              [8.96548867e-01, 2.93034434e-01, 5.23700714e-02,\n",
              "               4.66383696e-02, 3.45339060e-01, 9.90470529e-01,\n",
              "               9.67285752e-01, 6.36311889e-01, 1.71997309e-01,\n",
              "               3.98589373e-02, 3.66045475e-01, 5.50078869e-01,\n",
              "               4.95531440e-01, 4.51392055e-01, 2.61353612e-01,\n",
              "               6.71226740e-01, 3.02927494e-01, 8.34289432e-01,\n",
              "               2.21775413e-01, 4.84277248e-01]],\n",
              "\n",
              "             [[3.73022079e-01, 2.46072412e-01, 3.58117104e-01,\n",
              "               4.27853465e-01, 6.73961163e-01, 9.27092791e-01,\n",
              "               3.45356345e-01, 5.90945125e-01, 7.55282640e-02,\n",
              "               9.46051955e-01, 7.25440502e-01, 2.13555098e-02,\n",
              "               9.63211536e-01, 6.59143925e-03, 9.61769819e-02,\n",
              "               1.57614112e-01, 8.63839269e-01, 7.40685463e-02,\n",
              "               1.54764175e-01, 1.27662539e-01],\n",
              "              [5.91229796e-01, 2.14100122e-01, 1.67573810e-01,\n",
              "               1.92027688e-01, 3.87608886e-01, 1.37943029e-02,\n",
              "               5.75331807e-01, 2.38584280e-01, 5.91475010e-01,\n",
              "               2.07999349e-01, 4.72309828e-01, 2.18504190e-01,\n",
              "               5.62216043e-01, 5.98111868e-01, 3.50712419e-01,\n",
              "               9.32108164e-01, 8.96690845e-01, 9.49527025e-01,\n",
              "               6.21761680e-01, 8.88010502e-01]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.append([2],[3],axis = 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4LV3zSbMB8P",
        "outputId": "06a962a8-f8e2-48be-a521-f59641a324b4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.concatenate([b,b2],axis =1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "TrBvhuY5HaeE",
        "outputId": "3ee50260-b114-4951-95f0-2439f0e079d7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-b6ed23dea3e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_canonicalize_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0marrays_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/util.py\u001b[0m in \u001b[0;36mcanonicalize_axis\u001b[0;34m(axis, num_dims)\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnum_dims\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"axis {axis} is out of bounds for array of dimension {num_dims}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = [2,3 ,4 ]\n",
        "c.append([3,45])"
      ],
      "metadata": {
        "id": "xIIgzoB2Hx8D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYPtDuNAH43v",
        "outputId": "213809db-4046-4a07-e52f-55ed8ae0cc99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, [3, 45]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/instadeepai/jumanji.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMWu06-soreA",
        "outputId": "9c2019b4-251a-4d2b-e437-42650deac8d5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/instadeepai/jumanji.git\n",
            "  Cloning https://github.com/instadeepai/jumanji.git to /tmp/pip-req-build-u0mkr_l_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/instadeepai/jumanji.git /tmp/pip-req-build-u0mkr_l_\n",
            "  Resolved https://github.com/instadeepai/jumanji.git to commit 10958866909d434ba50edc1915247e4cebc3cb3e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (1.21.6)\n",
            "Requirement already satisfied: gym>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.25.2)\n",
            "Collecting chex>=0.1.3\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brax>=0.0.10\n",
            "  Downloading brax-0.1.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.3/471.3 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jaxlib>=0.1.74 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.3.25+cuda11.cudnn805)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (4.4.0)\n",
            "Collecting pygame>=2.0.0\n",
            "  Downloading pygame-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/21.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-env>=1.5\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: jax>=0.2.26 in /usr/local/lib/python3.8/dist-packages (from jumanji==0.1.4) (0.3.25)\n",
            "Collecting Pillow>=9.0.0\n",
            "  Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib>=3.3.4\n",
            "  Downloading matplotlib-3.6.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.3.0)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.51.1)\n",
            "Collecting pytinyrenderer\n",
            "  Downloading pytinyrenderer-0.0.13-cp38-cp38-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trimesh==3.9.35\n",
            "  Downloading trimesh-3.9.35-py3-none-any.whl (639 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m639.3/639.3 KB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mujoco\n",
            "  Downloading mujoco-2.3.1.post1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax\n",
            "  Downloading flax-0.6.4-py3-none-any.whl (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.3/204.3 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (2.11.3)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 KB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optax\n",
            "  Downloading optax-0.1.4-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 KB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from brax>=0.0.10->jumanji==0.1.4) (1.7.3)\n",
            "Collecting jaxopt\n",
            "  Downloading jaxopt-0.5.5-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from trimesh==3.9.35->brax>=0.0.10->jumanji==0.1.4) (57.4.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.3->jumanji==0.1.4) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.8/dist-packages (from chex>=0.1.3->jumanji==0.1.4) (0.1.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (2.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (6.0.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym>=0.22.0->jumanji==0.1.4) (0.0.8)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.8/dist-packages (from jax>=0.2.26->jumanji==0.1.4) (3.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (3.0.9)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.3.4->jumanji==0.1.4) (2.8.2)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym>=0.22.0->jumanji==0.1.4) (3.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->jumanji==0.1.4) (1.15.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.8/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.4) (1.0.4)\n",
            "Collecting orbax\n",
            "  Downloading orbax-0.1.1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorstore\n",
            "  Downloading tensorstore-0.1.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich>=11.1\n",
            "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.8/dist-packages (from flax->brax>=0.0.10->jumanji==0.1.4) (6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->brax>=0.0.10->jumanji==0.1.4) (2.0.1)\n",
            "Collecting glfw\n",
            "  Downloading glfw-2.5.6-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.8/dist-packages (from mujoco->brax>=0.0.10->jumanji==0.1.4) (3.1.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX->brax>=0.0.10->jumanji==0.1.4) (3.19.6)\n",
            "Collecting pygments<3.0.0,>=2.14.0\n",
            "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting markdown-it-py<3.0.0,>=2.1.0\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cached_property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.8/dist-packages (from orbax->flax->brax>=0.0.10->jumanji==0.1.4) (5.10.2)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.8/dist-packages (from orbax->flax->brax>=0.0.10->jumanji==0.1.4) (1.0.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: jumanji\n",
            "  Building wheel for jumanji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jumanji: filename=jumanji-0.1.4-py3-none-any.whl size=166864 sha256=13e31fdcaab7f7b13a3c88285240ff8e7d6dff0c44ec9cb9742d6ecbcbe6537e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wsuydpsi/wheels/df/c6/15/caef8b041b929f4f3b7a55a217c00f24c6931fe57ae40d9bd9\n",
            "Successfully built jumanji\n",
            "Installing collected packages: pytinyrenderer, glfw, dataclasses, cached_property, trimesh, tensorstore, tensorboardX, pygments, pygame, Pillow, mujoco, mdurl, fonttools, dm-env, contourpy, matplotlib, markdown-it-py, rich, jaxopt, chex, optax, orbax, flax, brax, jumanji\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.4.0 brax-0.1.1 cached_property-1.5.2 chex-0.1.5 contourpy-1.0.7 dataclasses-0.6 dm-env-1.6 flax-0.6.4 fonttools-4.38.0 glfw-2.5.6 jaxopt-0.5.5 jumanji-0.1.4 markdown-it-py-2.1.0 matplotlib-3.6.3 mdurl-0.1.2 mujoco-2.3.1.post1 optax-0.1.4 orbax-0.1.1 pygame-2.1.2 pygments-2.14.0 pytinyrenderer-0.0.13 rich-13.3.1 tensorboardX-2.5.1 tensorstore-0.1.30 trimesh-3.9.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upuzSlMOHB8T",
        "outputId": "8432493b-7c3f-4abb-9e94-f9a0331ab034"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import jax\n",
        "from jax import vmap\n",
        "import jax.numpy as jnp\n",
        "import jumanji\n",
        "from jumanji.wrappers import AutoResetWrapper\n",
        "import flax.linen as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def flatten_jax(obs):\n",
        "    return jnp.concatenate([obs.ems.x1,obs.ems.x2,\n",
        "                        obs.ems.y1,obs.ems.y2,\n",
        "                        obs.ems.z1,obs.ems.z2,\n",
        "                        obs.ems_mask.flatten(),obs.items.x_len,\n",
        "                        obs.items.y_len,obs.items.z_len,\n",
        "                        obs.items_mask.flatten(),obs.items_placed.flatten()])"
      ],
      "metadata": {
        "id": "Ya00mTGWHGBJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flax import linen as nn \n",
        "import optax\n",
        "\n",
        "class SimpleClassifierCompact(nn.Module):\n",
        "    num_hidden : int   # Number of hidden neurons\n",
        "    num_outputs : int  # Number of output neurons\n",
        "\n",
        "    @nn.compact  # Tells Flax to look for defined submodules\n",
        "    def __call__(self, x):\n",
        "        # Perform the calculation of the model to determine the prediction\n",
        "        # while defining necessary layers\n",
        "        x = nn.Dense(features=self.num_hidden)(x)\n",
        "        x = nn.tanh(x)\n",
        "        x = nn.Dense(features=self.num_outputs)(x)\n",
        "        return x\n",
        "def critic_calculate_loss( state, V,batch_rtgs):\n",
        "    #logits = critic_state.apply_fn(params, data).squeeze(axis=-1)\n",
        "    loss = optax.sigmoid_binary_cross_entropy(V, batch_rtgs).mean()\n",
        "    print(\"loss of critic \", loss)\n",
        "    return loss\n",
        "\n",
        "@jax.jit  # Jit the function for efficiency\n",
        "def critic_train_step(state, V,batch_rtgs):\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(critic_calculate_loss,  # Function to calculate the loss\n",
        "                                 argnums=1  # Parameters are second argument of the function\n",
        "                                 #has_aux=False  # Function has additional outputs, here accuracy\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    loss, grads = grad_fn(state.params,V,batch_rtgs)\n",
        "    print(\"gradient of critic \",grads,\" type \", type(grads))\n",
        "\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state\n",
        "def actor_calculate_loss( state, surr1,surr2):\n",
        "    #logits = critic_state.apply_fn(params, data).squeeze(axis=-1)\n",
        "    actor_loss = (-jnp.min(surr1, surr2)).mean()\n",
        "    print(\"actor loss \",actor_loss)\n",
        "    return actor_loss\n",
        "\n",
        "@jax.jit  # Jit the function for efficiency\n",
        "def actor_train_step(state,  surr1,surr2):\n",
        "    # Gradient function\n",
        "    grad_fn = jax.value_and_grad(actor_calculate_loss,  # Function to calculate the loss\n",
        "                                 argnums=1  # Parameters are second argument of the function\n",
        "                                 #has_aux=False  # Function has additional outputs, here accuracy\n",
        "                                )\n",
        "    # Determine gradients for current model, parameters and batch\n",
        "    loss, grads = grad_fn(state.params, surr1,surr2)\n",
        "    print(\"gradient of actor \",grads,\" type \", type(grads))\n",
        "    # Perform parameter update with gradients and optimizer\n",
        "    state = state.apply_gradients(grads=grads)\n",
        "    # Return state and any other value we might want\n",
        "    return state\n",
        "#critic_state, loss = critic_train_step(critic_state, data)"
      ],
      "metadata": {
        "id": "XOsEpJk7HMjx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "obs_dim = 380\n",
        "act_dim = 800\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "key, subkey = jax.random.split(key)\n",
        "optimizer = optax.sgd(learning_rate=lr)\n",
        "\n",
        "actor = SimpleClassifierCompact(num_hidden=64, num_outputs=act_dim)\n",
        "critic = SimpleClassifierCompact(num_hidden=64, num_outputs=1)\n",
        "\n",
        "params =actor.init(subkey, jnp.arange(obs_dim))\n",
        "cparams =critic.init(subkey, jnp.arange(obs_dim))\n",
        "actor_state = train_state.TrainState.create(apply_fn=actor.apply,\n",
        "                                        params=params,\n",
        "                                        tx=optimizer)\n",
        "critic_state = train_state.TrainState.create(apply_fn=critic.apply,\n",
        "                                        params=cparams,\n",
        "                                        tx=optimizer)\n",
        "a = actor_state.apply_fn(actor_state.params, i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "yc67jydbUsoY",
        "outputId": "7766feb9-8f25-4487-ac80-c9ea11d5678c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-71d3314e9ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                         tx=optimizer)\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b =critic_state.apply_fn(critic_state.params, i)"
      ],
      "metadata": {
        "id": "qknAPYbFWnTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "NS8neCS2XEUA",
        "outputId": "2c5da19b-5c2a-445b-e0ce-cd5f62ac2865"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-89e6c98d9288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flax.training import train_state\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "\n",
        "class PPO:\n",
        "  def __init__(self,env):\n",
        "    self._init_hyperparameters()\n",
        "    self.env = env\n",
        "    \n",
        "    #initiate actor and critic\n",
        "    \n",
        "\n",
        "    self.optimizer = optax.sgd(learning_rate=self.lr)\n",
        "\n",
        "    self.actor = SimpleClassifierCompact(num_hidden=64, num_outputs=self.act_dim)\n",
        "    self.critic = SimpleClassifierCompact(num_hidden=64, num_outputs=1)\n",
        "    \n",
        "    self.params = self.actor.init(self.subkey, jnp.arange(self.obs_dim))\n",
        "    self.cparams = self.critic.init(self.subkey, jnp.arange(self.obs_dim))\n",
        "\n",
        "    self.actor_state = train_state.TrainState.create(apply_fn=self.actor.apply,\n",
        "                                            params=self.params,\n",
        "                                            tx=self.optimizer)\n",
        "    self.critic_state = train_state.TrainState.create(apply_fn=self.critic.apply,\n",
        "                                            params=self.cparams,\n",
        "                                            tx=self.optimizer)\n",
        "     \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "  def _init_hyperparameters(self):\n",
        "    # Default values for hyperparameters, will need to change later.\n",
        "    self.timesteps_per_batch = 2  #4800            # timesteps per batch\n",
        "    #self.max_timesteps_per_episode = 1600      # timesteps per episode\n",
        "    self.gamma = 0.95\n",
        "    self.n_updates_per_iteration = 1\n",
        "    self.clip = 0.2 # As recommended by the paper\n",
        "    self.lr = 0.1\n",
        "\n",
        "    self.obs_dim = 380\n",
        "    self.act_dim = 800\n",
        "\n",
        "    self.key = jax.random.PRNGKey(0)\n",
        "    self.key, self.subkey = jax.random.split(self.key)\n",
        "\n",
        "\n",
        "  def compute_rtgs_jax(self, batch_rews): \n",
        "    # The rewards-to-go (rtg) per episode per batch to return.\n",
        "    # The shape will be (num timesteps per episode)\n",
        "    \n",
        "    batch_rtgs = jnp.array([])\n",
        "    print(\"batch_rews \",batch_rews)\n",
        "    # Iterate through each episode backwards to maintain same order in batch_rtgs\n",
        "    for ep_rews in reversed(batch_rews):\n",
        "      discounted_reward = 0 # The discounted reward so far\n",
        "      print(\" ep_rews \",ep_rews)\n",
        "      discounted_reward = ep_rews + discounted_reward * self.gamma\n",
        "      print(\"discounted_reward \",discounted_reward)\n",
        "      batch_rtgs = jnp.insert(batch_rtgs, 0, discounted_reward)\n",
        "    print(\"batch_rtgs\",batch_rtgs)\n",
        "    return batch_rtgs\n",
        "\n",
        "\n",
        " \n",
        "  def get_action_jax(self, obs, action_jnp):\n",
        "    #flatten observation  p = flatten(timestep.observation)\n",
        "    # inside critic and actor by converting it to np.array(p) by actor you will get action\n",
        "\n",
        "    #initiate actor and critic\n",
        "     #actor = FeedForwardNN(380,800)\n",
        "     logits = self.actor_state.apply_fn(self.actor_state.params, obs)\n",
        "    \n",
        "     valid_indices = jnp.nonzero(action_jnp)  # getting valid indicies\n",
        "     valid_logits = logits[valid_indices]  # getting proper valid action probablities\n",
        "     valid_logits_array = jnp.reshape(valid_logits, (-1,))  # reshapping it to make it 1D\n",
        "     index_mapping = [i for i, include in enumerate(action_jnp) if include] # mapping of valid actions on whole set of actions\n",
        "     # Gumbel's trick\n",
        "     \n",
        "     u = jax.random.uniform(self.subkey, shape=valid_logits_array.shape) # generates random uniform values\n",
        "     \n",
        "     probs = valid_logits_array - jnp.log(-jnp.log(u)) # logits + random uniform noise\n",
        "     action = jnp.argmax(probs) # argmax of probs -> action id in filtered array from valid actions\n",
        "     action_id = index_mapping[action] # action index in the 800 size array from actor output\n",
        "     log_prob_action = jnp.log(action) # log probability of selected action\n",
        "     \n",
        "     return action_id, action, log_prob_action\n",
        "  \n",
        "  def rollout(self):\n",
        "    # batch observations, batch actions, log probs of each action, batch rewards,batch rewards-to-go,episodic lengths in batch\n",
        "    batch_obs, batch_acts, batch_log_probs, batch_rews, batch_rtgs, batch_lens = jnp.array([]), jnp.array([]), jnp.array([]), jnp.array([]), jnp.array([]),jnp.array([])\n",
        "    batch_states = []\n",
        "    step_fn = jax.jit(self.env.step)\n",
        "    reset_fn = jax.jit(self.env.reset)\n",
        "    t = 0 \n",
        "    \n",
        "    while t < self.timesteps_per_batch: # Number of timesteps run so far this batch\n",
        "      # Rewards this episode\n",
        "      ep_rews = jnp.array([])\n",
        "      \n",
        "      \n",
        "      state, timestep = reset_fn(self.key)\n",
        "      ep_t = 1\n",
        "      rew = 0.0\n",
        "      while rew == 0.0:\n",
        "        batch_states.append(state)\n",
        "        obs = flatten_jax(timestep.observation)  # Collect observation\n",
        "        #print(\"obs  flat \",len(obs))\n",
        "        if t == 0 and ep_t == 1:\n",
        "          batch_obs = jnp.append(batch_obs, obs)\n",
        "        else:\n",
        "          batch_obs = jnp.vstack([batch_obs, obs])\n",
        "        #print(\"batch  \",batch_obs)\n",
        "        num_ems, num_items = self.env.action_spec().num_values\n",
        "        action_mask = timestep.observation.action_mask.flatten()\n",
        "        action_jnp = jnp.array(action_mask, dtype=jnp.float32)\n",
        "\n",
        "        ems_item_id, action_,log_prob  = self.get_action_jax(obs,action_jnp)\n",
        "        ems_id, item_id = jnp.divmod(ems_item_id, num_items)\n",
        "\n",
        "        action = jnp.array([ems_id, item_id])  # Wrap the action as a jax array of shape (2,)\n",
        "        #batch_states = jnp.append(batch_states, state)\n",
        "\n",
        "        state,timestep = step_fn(state, action)\n",
        "        rew = jnp.array(timestep.reward.flatten())[0]\n",
        "        #print(\" rew \", rew,\" type \", type(rew))\n",
        "        ep_rews = jnp.append(ep_rews, rew)\n",
        "        #print(\" ep_rews \",ep_rews )\n",
        "        batch_acts = jnp.append(batch_acts, action_)\n",
        "        batch_log_probs = jnp.append(batch_log_probs, log_prob)\n",
        "        ep_t += 1 # Increment timesteps ran this batch so far\n",
        "\n",
        "      t += ep_t\n",
        "      batch_rews = jnp.append(batch_rews, ep_rews) \n",
        "    \n",
        "    batch_rtgs = self.compute_rtgs_jax(batch_rews)\n",
        "    return batch_obs, batch_acts,batch_log_probs, batch_rtgs, t ,rew,batch_states\n",
        "\n",
        "  def learn(self, total_timesteps):\n",
        "    t_so_far = 0 # Timesteps simulated so far\n",
        "    episode_reward = jnp.array([])\n",
        "    while t_so_far < total_timesteps:              # ALG STEP \n",
        "      batch_obs, batch_acts, batch_log_probs, batch_rtgs, t, rew,batch_states = self.rollout()\n",
        "      # print(\"len  of batch obs and obs of episode itself\",len(batch_obs),batch_obs)\n",
        "      # print(\"batch_ act \", batch_acts)\n",
        "      # print(\"batch_log_prob \",batch_log_probs)\n",
        "      # print(\"batch_rtg \", batch_rtgs)\n",
        "      \n",
        "      episode_reward = jnp.append(episode_reward, rew)\n",
        "      t_so_far += t # Calculate how many timesteps we collected this batch   \n",
        "      V, _ = self.evaluate(batch_obs, batch_acts)\n",
        "      A_k = batch_rtgs - V # ALG STEP 5 Calculate advantage\n",
        "      A_k = (A_k - A_k.mean()) / (A_k.std() + 1e-10) # Normalize advantages\n",
        "      for i in range(self.n_updates_per_iteration):\n",
        "        V, curr_log_probs = self.evaluate(batch_obs, batch_acts)\n",
        "        ratios = jax.lax.exp(curr_log_probs - batch_log_probs)   # Calculate ratios\n",
        "        surr1 = ratios * A_k  # Calculate surrogate losses\n",
        "        surr2 = jax.lax.clamp( 1 - self.clip, ratios, 1 + self.clip) * A_k\n",
        "        print(surr1,surr2,\"  surrrrrr  \",\"  ratios \",ratios, \" ak \",A_k)\n",
        "        \n",
        "        self.actor_state = actor_train_step(self.actor_state, surr1, surr2)\n",
        "        self.critic_state = critic_train_step(self.critic_state, V, batch_rtgs)\n",
        "        \n",
        "        \n",
        "    return batch_states, episode_reward\n",
        "    \n",
        "  def evaluate(self, batch_obs,batch_acts):\n",
        "    # Query critic network for a value V for each obs in batch_obs.\n",
        "    #V = self.critic(batch_obs).squeeze()\n",
        "#vmap(sum_samples)(data)\n",
        "    #V = vmap(self.critic_state.apply_fn)(self.critic_state.params, batch_obs)#.squeeze(axis=-1)\n",
        "    V = jnp.array([])\n",
        "    #batch_logits = jnp.array([])\n",
        "    for i in batch_obs:\n",
        "      \n",
        "      # print(\"len of actor param \", len(self.actor_state.params),self.actor_state.params)\n",
        "\n",
        "      #batch_logits = jnp.append(batch_logits,self.actor_state.apply_fn(self.actor_state.params, i))\n",
        "      # print(\"len of out actor \",len(outa), outa )\n",
        "      # print(\"critic param \",len(self.critic_state.params),self.critic_state.params)\n",
        "      # print(\"obs \", len(i))\n",
        "      V = jnp.append(V,self.critic_state.apply_fn(self.critic_state.params, i))\n",
        "    #print(\"Value func \", V)\n",
        "    #print(\"batch_logits \",batch_logits)\n",
        "    # Calculate the log probabilities of batch actions using most \n",
        "    # recent actor network.  # This segment of code is similar to that in get_action()\n",
        "    #batch_logits = self.actor_state.apply_fn(self.actor_state.params, batch_obs).squeeze(axis=-1)\n",
        "    # rescaling \n",
        "    #log_softmax_probs = jax.nn.log_softmax(batch_logits)\n",
        "    # print(\"log_softmax_probs len \",type(log_softmax_probs),log_softmax_probs)\n",
        "    # print(\"batch_ actions \", type(batch_acts),batch_acts)\n",
        "    log_probs = jnp.log(batch_acts)\n",
        "\n",
        "    return V, log_probs  # Return predicted values V and log probs log_probs\n",
        " \n",
        "  "
      ],
      "metadata": {
        "id": "UjzPa8LFHNvL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "env = jumanji.make(\"BinPack-toy-v0\")\n",
        "model = PPO(env)\n",
        "#batch_obs, batch_acts, batch_log_probs, batch_rtgs, t, rew = model.rollout()\n",
        "  \n",
        "%time batch_states, episode_rewards = model.learn(1)\n",
        "#### with jit env , reset one episode \n",
        "# CPU times: user 7.4 s, sys: 103 ms, total: 7.5 s\n",
        "# Wall time: 7.1 s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x-37ugMco8ka",
        "outputId": "198aa426-267d-4a0a-a42f-f0ed5f44b0b8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/ops/scatter.py:87: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=float32 to dtype=int32. In future JAX releases this will result in an error.\n",
            "  warnings.warn(\"scatter inputs have incompatible types: cannot safely cast \"\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n",
            "/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/lax_numpy.py:173: UserWarning: Explicitly requested dtype float64 requested in asarray is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
            "  return asarray(x, dtype=self.dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_rews  [0.        0.        0.        0.        0.        0.        0.\n",
            " 0.        0.        0.        0.        0.        0.        0.6203638]\n",
            " ep_rews  0.6203638\n",
            "discounted_reward  0.6203638\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            " ep_rews  0.0\n",
            "discounted_reward  0.0\n",
            "batch_rtgs [0.        0.        0.        0.        0.        0.        0.\n",
            " 0.        0.        0.        0.        0.        0.        0.6203638]\n",
            "[ 0.92711484  1.1275     -0.8375287   1.3411393   0.29414117 -0.17339565\n",
            " -0.51581496 -0.6962916   0.15005463 -0.8802864  -0.6120951  -2.0183198\n",
            "         nan         nan] [ 0.92711484  1.1275     -0.8375287   1.3411393   0.29414117 -0.17339565\n",
            " -0.51581496 -0.6962916   0.15005463 -0.8802864  -0.6120951  -2.0183198\n",
            "         nan         nan]   surrrrrr     ratios  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan]  ak  [ 0.92711484  1.1275     -0.8375287   1.3411393   0.29414117 -0.17339565\n",
            " -0.51581496 -0.6962916   0.15005463 -0.8802864  -0.6120951  -2.0183198\n",
            "  0.09169656  1.8020861 ]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ConcretizationTypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-adbb6a51dcbf>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt_so_far\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m# ALG STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0mbatch_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rtgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m       \u001b[0;31m# print(\"len  of batch obs and obs of episode itself\",len(batch_obs),batch_obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m         jax.config.jax_debug_nans or jax.config.jax_debug_infs):\n\u001b[0;32m--> 622\u001b[0;31m       \u001b[0mexecute\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xla_call_impl_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m       \u001b[0mout_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_bind_continuation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_call_impl_lazy\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0marg_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_device'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m   return xla_callable(fun, device, backend, name, donated_invars, keep_unused,\n\u001b[0m\u001b[1;32m    237\u001b[0m                       *arg_specs)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     return lower_xla_callable(fun, device, backend, name, donated_invars, False,\n\u001b[0m\u001b[1;32m    360\u001b[0m                               keep_unused, *arg_specs).compile().unsafe_call\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mlower_xla_callable\u001b[0;34m(fun, device, backend, name, donated_invars, always_lower, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                         \"for jit in {elapsed_time} sec\"):\n\u001b[0;32m--> 445\u001b[0;31m     jaxpr, out_type, consts = pe.trace_to_jaxpr_final2(\n\u001b[0m\u001b[1;32m    446\u001b[0m         fun, pe.debug_info_final(fun, \"jit\"))\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_final2\u001b[0;34m(fun, debug_info)\u001b[0m\n\u001b[1;32m   2076\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_sublevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_dynamic2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_subjaxpr_dynamic2\u001b[0;34m(fun, main, debug_info)\u001b[0m\n\u001b[1;32m   2026\u001b[0m     \u001b[0min_tracers_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_inputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2027\u001b[0;31m     \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0min_tracers_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2028\u001b[0m     \u001b[0mout_tracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-9d330f67ec6f>\u001b[0m in \u001b[0;36mactor_train_step\u001b[0;34m(state, surr1, surr2)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Determine gradients for current model, parameters and batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient of actor \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" type \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2656\u001b[0;31m     out_primal, out_vjp = ad.vjp(\n\u001b[0m\u001b[1;32m   2657\u001b[0m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr_nounits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr_nounits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-9d330f67ec6f>\u001b[0m in \u001b[0;36mactor_calculate_loss\u001b[0;34m(state, surr1, surr2)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#logits = critic_state.apply_fn(params, data).squeeze(axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"actor loss \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    267\u001b[0m         where: Optional[ArrayLike] = None) -> Array:\n\u001b[0;32m--> 268\u001b[0;31m   return _reduce_min(a, axis=_ensure_optional_axes(axis), out=out,\n\u001b[0m\u001b[1;32m    269\u001b[0m                      keepdims=keepdims, initial=initial, where=where)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36m_ensure_optional_axes\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m   return core.concrete_or_error(\n\u001b[0m\u001b[1;32m    189\u001b[0m     force, x, \"The axis argument must be known statically.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mconcrete_or_error\u001b[0;34m(force, val, context)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mConcretizationTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m: jax._src.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(float32[14])>with<DynamicJaxprTrace(level=0/1)>\nThe axis argument must be known statically.\nThe error occurred while tracing the function actor_train_step at <ipython-input-43-9d330f67ec6f>:43 for jit. This concrete value was not available in Python because it depends on the value of the argument 'surr2'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-adbb6a51dcbf>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mepisode_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mt_so_far\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m              \u001b[0;31m# ALG STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       \u001b[0mbatch_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_log_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rtgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m       \u001b[0;31m# print(\"len  of batch obs and obs of episode itself\",len(batch_obs),batch_obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0;31m# print(\"batch_ act \", batch_acts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-9d330f67ec6f>\u001b[0m in \u001b[0;36mactor_train_step\u001b[0;34m(state, surr1, surr2)\u001b[0m\n\u001b[1;32m     49\u001b[0m                                 )\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# Determine gradients for current model, parameters and batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient of actor \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" type \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Perform parameter update with gradients and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-9d330f67ec6f>\u001b[0m in \u001b[0;36mactor_calculate_loss\u001b[0;34m(state, surr1, surr2)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mactor_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msurr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m#logits = critic_state.apply_fn(params, data).squeeze(axis=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"actor loss \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactor_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36mmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mArrayLike\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         where: Optional[ArrayLike] = None) -> Array:\n\u001b[0;32m--> 268\u001b[0;31m   return _reduce_min(a, axis=_ensure_optional_axes(axis), out=out,\n\u001b[0m\u001b[1;32m    269\u001b[0m                      keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/jax/_src/numpy/reductions.py\u001b[0m in \u001b[0;36m_ensure_optional_axes\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m   return core.concrete_or_error(\n\u001b[0m\u001b[1;32m    189\u001b[0m     force, x, \"The axis argument must be known statically.\")\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(float32[14])>with<DynamicJaxprTrace(level=0/1)>\nThe axis argument must be known statically.\nThe error occurred while tracing the function actor_train_step at <ipython-input-43-9d330f67ec6f>:43 for jit. This concrete value was not available in Python because it depends on the value of the argument 'surr2'.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YXP4lrq-wAjS"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}